# ==============================================================================
# ECHO - Voice Recording & Transcription (Development Mode)
# ==============================================================================
# Connects to FORGE workspace infrastructure
#
# Usage:
#   cd D:\Projects\AXIOM\apps\echo
#   docker-compose -f docker-compose.dev.yml up -d
#
# Prerequisites:
#   - forge-network must exist (created by FORGE)
#   - forge-postgres must be running
#   - forge-redis must be running
#   - NVIDIA Container Toolkit installed (for GPU support)
# ==============================================================================

services:
  # ============================================================================
  # BACKEND - FastAPI Application with GPU Support
  # ============================================================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: echo-backend
    ports:
      - "7201:8000"
    volumes:
      - ./backend:/app
      - ./data:/app/data
      - backend-cache:/app/__pycache__
      - whisper-models:/app/models
    environment:
      # Database (FORGE PostgreSQL)
      DATABASE_URL: postgresql://postgres:postgres@forge-postgres:5432/echo
      POSTGRES_SERVER: forge-postgres
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: echo

      # Redis (FORGE Redis)
      REDIS_URL: redis://forge-redis:6379
      REDIS_KEY_PREFIX: "echo:"

      # JWT (shared with AXIOM workspace)
      SECRET_KEY: ${WORKSPACE_SECRET_KEY:-dev-secret-key-change-in-production-min-32-chars}
      ALGORITHM: HS256
      ACCESS_TOKEN_EXPIRE_MINUTES: 60

      # CORS
      CORS_ORIGINS: "http://localhost:7200,http://localhost:5173"

      # Application
      ENVIRONMENT: development
      DEBUG: "true"
      LOG_LEVEL: DEBUG
      APP_NAME: ECHO
      APP_VERSION: 0.1.0

      # Whisper Configuration (Auto-detect: NPU > CPU)
      # NPU: AMD Ryzen AI (requires SDK 1.6.1 installed on host)
      # CPU: faster-whisper fallback (always available)
      WHISPER_DEVICE: auto
      WHISPER_MODEL: base           # CPU fallback model
      WHISPER_MODEL_NPU: medium     # NPU model (faster with BFP16)
      WHISPER_COMPUTE_TYPE: int8    # CPU compute type
      WHISPER_PRECISION: bfp16      # NPU native precision

      # Audio
      AUDIO_STORAGE_PATH: /app/data
      DEFAULT_SAMPLE_RATE: 44100
      DEFAULT_LANGUAGE: auto

      # Logging
      LOKI_URL: http://loki:3100

    labels:
      logging: "promtail"
      logging_jobname: "echo-backend"

    command: python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    networks:
      - forge-network
    restart: unless-stopped

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ============================================================================
  # FRONTEND - React + Vite Development Server
  # ============================================================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: echo-frontend
    ports:
      - "7200:5173"
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/index.html:/app/index.html
      - ./frontend/vite.config.ts:/app/vite.config.ts
      - ./frontend/tailwind.config.js:/app/tailwind.config.js
      - ./frontend/tsconfig.json:/app/tsconfig.json
      - /app/node_modules
    environment:
      VITE_API_URL: http://localhost:7201
      VITE_WS_URL: ws://localhost:7201
      NODE_ENV: development
      VITE_APP_NAME: ECHO
      VITE_APP_VERSION: 0.1.0

    labels:
      logging: "promtail"
      logging_jobname: "echo-frontend"

    networks:
      - forge-network
    depends_on:
      - backend
    restart: unless-stopped

    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:5173"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

# ==============================================================================
# VOLUMES
# ==============================================================================
volumes:
  backend-cache:
    driver: local
  whisper-models:
    driver: local
    # Persist Whisper models across container restarts
    # Models are downloaded on first use (~3GB for large-v3)

# ==============================================================================
# NETWORKS
# ==============================================================================
networks:
  forge-network:
    external: true
    name: forge-network

# ==============================================================================
# NOTES
# ==============================================================================
# 1. Hardware Acceleration (Auto-detected in order):
#    Priority 1: NPU (AMD Ryzen AI) - Requires SDK 1.6.1 on host
#    Priority 2: CPU (faster-whisper) - Always available fallback
#    Note: GPU skipped - Radeon 890M (gfx1150) not supported by ROCm
#
# 2. NPU Setup (for Ryzen AI 300 series):
#    a. Verify NPU in Task Manager > Performance > NPU0
#    b. Download Ryzen AI SDK 1.6.1 from AMD
#    c. Install: .\ryzenai-lt-1.6.1.exe
#    d. Activate: conda activate ryzenai-1.6.1
#
# 3. First startup will download Whisper model:
#    - base: ~150MB (CPU)
#    - medium: ~1.5GB (NPU)
#
# 4. Access:
#    - Frontend: http://localhost:7200
#    - Backend API: http://localhost:7201/docs
#    - Health: http://localhost:7201/api/v1/health
#
# 5. Database:
#    - Connect: docker exec -it forge-postgres psql -U postgres -d echo
#
# 6. Audio files stored in ./data/ directory
#
# 7. Performance (30s audio transcription):
#    - NPU (medium): ~5s
#    - CPU (base): ~5s
#    - CPU (medium): ~15s
# ==============================================================================
